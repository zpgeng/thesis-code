{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UCI Wine with VAE.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okccl8zJrtWG"
      },
      "source": [
        "## Preprosssing on UCI Wine Quality dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ufy7VrQMR2p"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import make_grid\n",
        "from scipy.stats import norm\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-DwNhKOd4hV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWyFp02KsxlJ"
      },
      "source": [
        "Here the dataset is generated using \n",
        "\n",
        "```\n",
        "real_data.R\n",
        "```\n",
        "\n",
        "You should first generate from R and import them here for the cross-language reproducibility.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5BsulpSz4Fi"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Thesis & Project/wine.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WW60t2uMeWc0"
      },
      "source": [
        "df = df.iloc[:, range(0,10)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "UWcYKqm6g7D8",
        "outputId": "b03e4100-ee19-45b0-8d8a-2532cf38ff97"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed.acidity</th>\n",
              "      <th>volatile.acidity</th>\n",
              "      <th>citric.acid</th>\n",
              "      <th>residual.sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free.sulfur.dioxide</th>\n",
              "      <th>total.sulfur.dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.0</td>\n",
              "      <td>0.270</td>\n",
              "      <td>0.36</td>\n",
              "      <td>20.7</td>\n",
              "      <td>0.045</td>\n",
              "      <td>45.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>1.0010</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.3</td>\n",
              "      <td>0.300</td>\n",
              "      <td>0.34</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.049</td>\n",
              "      <td>14.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>0.9940</td>\n",
              "      <td>3.30</td>\n",
              "      <td>0.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.1</td>\n",
              "      <td>0.280</td>\n",
              "      <td>0.40</td>\n",
              "      <td>6.9</td>\n",
              "      <td>0.050</td>\n",
              "      <td>30.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>0.9951</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.2</td>\n",
              "      <td>0.230</td>\n",
              "      <td>0.32</td>\n",
              "      <td>8.5</td>\n",
              "      <td>0.058</td>\n",
              "      <td>47.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>0.9956</td>\n",
              "      <td>3.19</td>\n",
              "      <td>0.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.2</td>\n",
              "      <td>0.230</td>\n",
              "      <td>0.32</td>\n",
              "      <td>8.5</td>\n",
              "      <td>0.058</td>\n",
              "      <td>47.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>0.9956</td>\n",
              "      <td>3.19</td>\n",
              "      <td>0.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>7.0</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.25</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.070</td>\n",
              "      <td>3.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0.9963</td>\n",
              "      <td>3.25</td>\n",
              "      <td>0.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>7.6</td>\n",
              "      <td>0.900</td>\n",
              "      <td>0.06</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.079</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.9967</td>\n",
              "      <td>3.39</td>\n",
              "      <td>0.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>8.1</td>\n",
              "      <td>0.545</td>\n",
              "      <td>0.18</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.080</td>\n",
              "      <td>13.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0.9972</td>\n",
              "      <td>3.30</td>\n",
              "      <td>0.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>8.3</td>\n",
              "      <td>0.610</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.1</td>\n",
              "      <td>0.084</td>\n",
              "      <td>11.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.9972</td>\n",
              "      <td>3.40</td>\n",
              "      <td>0.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.30</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>8.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0.9959</td>\n",
              "      <td>3.31</td>\n",
              "      <td>0.56</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows Ã— 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      fixed.acidity  volatile.acidity  citric.acid  ...  density    pH  sulphates\n",
              "0               7.0             0.270         0.36  ...   1.0010  3.00       0.45\n",
              "1               6.3             0.300         0.34  ...   0.9940  3.30       0.49\n",
              "2               8.1             0.280         0.40  ...   0.9951  3.26       0.44\n",
              "3               7.2             0.230         0.32  ...   0.9956  3.19       0.40\n",
              "4               7.2             0.230         0.32  ...   0.9956  3.19       0.40\n",
              "...             ...               ...          ...  ...      ...   ...        ...\n",
              "4995            7.0             0.500         0.25  ...   0.9963  3.25       0.63\n",
              "4996            7.6             0.900         0.06  ...   0.9967  3.39       0.56\n",
              "4997            8.1             0.545         0.18  ...   0.9972  3.30       0.59\n",
              "4998            8.3             0.610         0.30  ...   0.9972  3.40       0.61\n",
              "4999            7.8             0.500         0.30  ...   0.9959  3.31       0.56\n",
              "\n",
              "[5000 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vNi2Lnh1FeR",
        "outputId": "d582edee-6920-4280-b78f-5eb9540a212c"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"GPU Enabled:\",torch.cuda.is_available())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Enabled: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTjbS4x1QL25"
      },
      "source": [
        "def setup_data_loaders(batch_size=100, use_cuda=False):\n",
        "  scaler = preprocessing.MinMaxScaler()\n",
        "  names = df.columns\n",
        "  d = scaler.fit_transform(df)\n",
        "  scaled_df = pd.DataFrame(d, columns=names)\n",
        "  scaled_data = scaled_df.to_numpy()\n",
        "  train_set = scaled_data[range(0, int(len(df) / 5 * 4)), ].astype(np.float32)\n",
        "  test_set = scaled_data[range(int(len(df) / 5 * 4), len(df)), ].astype(np.float32)\n",
        "  data_loader = DataLoader(dataset=scaled_data.astype(np.float32), batch_size=len(df), shuffle=True)\n",
        "  train_loader = DataLoader(dataset=train_set,\n",
        "                            batch_size=batch_size, shuffle=True)\n",
        "  test_loader = DataLoader(dataset=test_set,\n",
        "                           batch_size=batch_size, shuffle=False)\n",
        "  return data_loader, train_loader, test_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8ZauaxdudMn"
      },
      "source": [
        "## Defining VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlKtRSZR2cPU"
      },
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.input_dim = df.shape[1]\n",
        "        self.encoder = nn.Sequential(nn.Linear(self.input_dim, 256),\n",
        "                                     nn.Softplus(),\n",
        "                                     nn.Linear(256, 128),\n",
        "                                     nn.BatchNorm1d(128),\n",
        "                                     nn.Softplus(),\n",
        "                                     nn.Linear(128, 64),\n",
        "                                     nn.BatchNorm1d(64),\n",
        "                                     nn.Softplus(),\n",
        "                                     nn.Linear(64, 8),\n",
        "                                     )\n",
        "        \n",
        "        self.mu     = nn.Linear(8, latent_dim)\n",
        "        self.logvar = nn.Linear(8, latent_dim)\n",
        "        \n",
        "        self.latent_mapping = nn.Linear(latent_dim, 8)\n",
        "        \n",
        "        self.decoder = nn.Sequential(nn.Linear(8, 16),\n",
        "                                     nn.Softplus(),\n",
        "                                     nn.BatchNorm1d(16),\n",
        "                                     nn.Linear(16, 64),\n",
        "                                     nn.Softplus(),\n",
        "                                     nn.BatchNorm1d(64),\n",
        "                                     nn.Linear(64, 128),\n",
        "                                     nn.Softplus(),\n",
        "                                     nn.BatchNorm1d(128),\n",
        "                                     nn.Linear(128, self.input_dim))        \n",
        "        \n",
        "    def encode(self, x):\n",
        "        #x = x.view(x.size(0), -1)\n",
        "        encoder = self.encoder(x)\n",
        "        mu, logvar = self.mu(encoder), self.logvar(encoder)\n",
        "        return mu, logvar\n",
        "        \n",
        "    def sample_z(self, mu, logvar):\n",
        "        eps = torch.rand_like(mu)\n",
        "        return mu + eps * torch.exp(0.5 * logvar)\n",
        "    \n",
        "    def decode(self, z, x):\n",
        "        latent_z = self.latent_mapping(z)\n",
        "        out = self.decoder(latent_z)\n",
        "        reshaped_out = torch.sigmoid(out).reshape((-1, self.input_dim))\n",
        "        return reshaped_out\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.sample_z(mu, logvar)\n",
        "        output = self.decode(z, x)\n",
        "        \n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qmN1TDe2vMR"
      },
      "source": [
        "def elbo_loss(x_generated, x_true, mu, logvar):\n",
        "    recon_loss = nn.functional.mse_loss(x_generated, x_true, reduction='none')\n",
        "    kld_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), 1).mean()\n",
        "    loss = torch.mean(kld_loss + recon_loss)\n",
        "    \n",
        "    return loss, torch.mean(recon_loss), torch.mean(kld_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIHkZODE4ser"
      },
      "source": [
        "# Define the functions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGu6PSPr4hSM"
      },
      "source": [
        "def training_function(latent_dimension, train, test):\n",
        "  vae_net = VAE(latent_dim = latent_dimension)\n",
        "  opt = torch.optim.Adam(vae_net.parameters())\n",
        "  max_epochs = 10\n",
        "\n",
        "  vae_net = vae_net.to(device)\n",
        "\n",
        "  for epoch in range(max_epochs):\n",
        "      \n",
        "      train_loss = 0.0\n",
        "      train_loss_rec = 0.0\n",
        "      train_loss_kdl = 0.0\n",
        "      \n",
        "      for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "          inputs = data\n",
        "\n",
        "          inputs = inputs.to(device)\n",
        "          \n",
        "          # training steps for normal model\n",
        "          opt.zero_grad()\n",
        "          \n",
        "          mu, logvar = vae_net.encode(inputs)\n",
        "          z = vae_net.sample_z(mu, logvar)\n",
        "          outputs = vae_net.decode(z, inputs)\n",
        "\n",
        "          loss, recon_loss, kld_loss = elbo_loss(outputs, inputs, mu, logvar)\n",
        "          loss.backward()\n",
        "          opt.step()   \n",
        "        \n",
        "          # print statistics\n",
        "          train_loss += loss.item()\n",
        "          train_loss_rec += recon_loss.item()\n",
        "          train_loss_kdl += kld_loss.item()\n",
        "\n",
        "    \n",
        "      test_loss = 0.0\n",
        "      test_loss_rec = 0.0\n",
        "      test_loss_kdl = 0.0\n",
        "\n",
        "      for i, data in enumerate(test_loader, 0):\n",
        "        inputs = data\n",
        "        inputs = inputs.to(device)\n",
        "        mu, logvar = vae_net.encode(inputs)\n",
        "        z = vae_net.sample_z(mu, logvar)\n",
        "        outputs = vae_net.decode(z, inputs)\n",
        "        \n",
        "        loss, recon_loss, kld_loss = elbo_loss(outputs, inputs, mu, logvar)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        test_loss_rec += recon_loss.item()\n",
        "        test_loss_kdl += kld_loss.item()\n",
        "\n",
        "\n",
        "      print(f'Epoch {epoch+1} \\t\\t Training Loss: {\\\n",
        "                                              train_loss / len(train_loader)} \\t\\t Validation Loss: {\\\n",
        "                                                                                                      test_loss / len(test_loader)}')\n",
        "  return vae_net\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wNYly97uVOo"
      },
      "source": [
        "## Training function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNGRuYxNtu1R"
      },
      "source": [
        "Started to train and save the corresponding latent confounder estimations. Then you can import them in R. With the same random seed in R, it can be guaranteed to experiment on the same dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jrKiG_XMzEO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80b69d42-f65f-4505-a75d-b9daa3cb0db9"
      },
      "source": [
        "data_loader, train_loader, test_loader = setup_data_loaders()\n",
        "vae_net = training_function(1, train_loader, test_loader)\n",
        "for _, data in enumerate(data_loader, 0):\n",
        "  inputs = data.to(device)\n",
        "  mu, logvar = vae_net.encode(inputs)\n",
        "  z = vae_net.sample_z(mu, logvar)\n",
        "  z_np = z.cpu().detach().numpy() #convert to Numpy array\n",
        "  df = pd.DataFrame(z_np) #convert to a dataframe\n",
        "  df.to_csv(\"zvae.csv\", index=False) #save to file"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 \t\t Training Loss: 0.12336255107074975 \t\t Validation Loss: 0.09397087320685386\n",
            "Epoch 2 \t\t Training Loss: 0.06656816257163882 \t\t Validation Loss: 0.04324515350162983\n",
            "Epoch 3 \t\t Training Loss: 0.021971254120580853 \t\t Validation Loss: 0.013279058784246445\n",
            "Epoch 4 \t\t Training Loss: 0.008760988037101925 \t\t Validation Loss: 0.009573898464441299\n",
            "Epoch 5 \t\t Training Loss: 0.007341346889734268 \t\t Validation Loss: 0.009184784861281515\n",
            "Epoch 6 \t\t Training Loss: 0.007110699242912233 \t\t Validation Loss: 0.009114605886861683\n",
            "Epoch 7 \t\t Training Loss: 0.007016649807337671 \t\t Validation Loss: 0.009064065106213093\n",
            "Epoch 8 \t\t Training Loss: 0.006934608181472868 \t\t Validation Loss: 0.008979910798370839\n",
            "Epoch 9 \t\t Training Loss: 0.006887508637737483 \t\t Validation Loss: 0.008904504124075174\n",
            "Epoch 10 \t\t Training Loss: 0.006891176127828658 \t\t Validation Loss: 0.00892068394459784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8nsEx8UgkAg"
      },
      "source": [
        "data_loader, train_loader, test_loader = setup_data_loaders()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "zAG6Ra-Ohb3X",
        "outputId": "5d0b7b4a-2ff5-41d8-ce19-0a6c294dabe4"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.900269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.078015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.276061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.067998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.706525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>0.675068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>0.683754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>0.091734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>0.859953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>0.344008</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows Ã— 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             0\n",
              "0     0.900269\n",
              "1     0.078015\n",
              "2     0.276061\n",
              "3     0.067998\n",
              "4     0.706525\n",
              "...        ...\n",
              "4995  0.675068\n",
              "4996  0.683754\n",
              "4997  0.091734\n",
              "4998  0.859953\n",
              "4999  0.344008\n",
              "\n",
              "[5000 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag7jmRMyhd5K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}